{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gurumoorthy1989/Guru/blob/master/Copy_of_Welcome_To_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "<p><img alt=\"Colaboratory logo\" height=\"45px\" src=\"/img/colab_favicon.ico\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "<h1>Welcome to Colaboratory!</h1>\n",
        "\n",
        "\n",
        "Colaboratory is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud.\n",
        "\n",
        "With Colaboratory you can write and execute code, save and share your analyses, and access powerful computing resources, all for free from your browser."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2r_wRFL3RmP",
        "colab_type": "code",
        "outputId": "5a86a732-aa84-4986-baa3-ad9d403b59d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!pip install -q sklearn\n",
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "import tensorflow.compat.v2.feature_column as fc\n",
        "import tensorflow as tf\n",
        "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n",
        "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\n",
        "y_train = dftrain.pop('survived')\n",
        "y_eval = dfeval.pop('survived')\n",
        "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses','parch', 'class', 'deck', 'embark_town', 'alone']\n",
        "NUMERIC_COLUMNS = ['age','fare']\n",
        "feature_columns = []\n",
        "for feature_name in CATEGORICAL_COLUMNS:\n",
        "    vocabulary = dftrain[feature_name].unique()\n",
        "    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name,vocabulary))\n",
        "for feature_name in NUMERIC_COLUMNS:\n",
        "    feature_columns.append(tf.feature_column.numeric_column(feature_name,dtype=tf.float32))\n",
        "print(feature_columns)\n",
        "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
        "  def input_function():\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(1000)\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    return ds\n",
        "  return input_function\n",
        "train_input_fn = make_input_fn(dftrain, y_train)\n",
        "eval_input_fn = make_input_fn(dftrain, y_eval, num_epochs=1, shuffle=False)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(1, 0, 3, 4, 2, 5, 8), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='parch', vocabulary_list=(0, 1, 2, 5, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0), NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8QwPXc66-AZ",
        "colab_type": "code",
        "outputId": "f638e2e3-b750-421e-bb94-bafafe173fef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
        "\n",
        "linear_est.train(train_input_fn)\n",
        "\n",
        "result = linear_est.evaluate(train_input_fn)\n",
        "\n",
        "clear_output()\n",
        "\n",
        "print(result['accuracy'])\n",
        "print(result)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.80701756\n",
            "{'accuracy': 0.80701756, 'accuracy_baseline': 0.61244017, 'auc': 0.8683288, 'auc_precision_recall': 0.8432804, 'average_loss': 0.42718956, 'label/mean': 0.3875598, 'loss': 0.42668313, 'precision': 0.7584746, 'prediction/mean': 0.40254092, 'recall': 0.7366255, 'global_step': 200}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-gy9C7jQt3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaOM1TulIft9",
        "colab_type": "code",
        "outputId": "d7fd76a7-506a-428b-fbb2-7898b6d4cf7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Classification\n",
        "!pip install -q sklearn\n",
        "%tensorflow_version 2.x\n",
        "#import and setup\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "import tensorflow.compat.v2.feature_column as fc\n",
        "import tensorflow as tf\n",
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species', ]\n",
        "SPECIES = ['Setosa', 'Versicolour', 'Virginica']\n",
        "train_path = tf.keras.utils.get_file(\n",
        "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
        "test_path = tf.keras.utils.get_file(\n",
        "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
        "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "\n",
        "train_y = train.pop('Species')\n",
        "test_y = test.pop('Species')\n",
        "\n",
        "#Input function\n",
        "def input_fn(features, labels, training=True, batch_size=256):\n",
        "    #convert the input into dataset\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "    #Shuffle and repeat if yuou are in training mode\n",
        "    if training:\n",
        "        dataset = dataset.shuffle(1000).repeat()\n",
        "    return dataset.batch(batch_size)\n",
        "\n",
        "#feature columns   \n",
        "my_feature_columns = []\n",
        "for key in train.keys():\n",
        "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
        "\n",
        "#Building the model\n",
        "#build a DNN (Deep Neural Network) with 2 hidden layer with 30 and 10 hidden nodes each.\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "    feature_columns=my_feature_columns,\n",
        "    #two hidden layersof 30 and 10 nodes respectively\n",
        "    hidden_units=[30, 10],\n",
        "    # the model must choose between 3 classes\n",
        "    n_classes=3)\n",
        "\n",
        "#Training the model\n",
        "classifier.train(\n",
        "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
        "    steps=5000)\n",
        "#calling function inside function x= lambda: print(\"hi\")---x()\n",
        "#last model we have return the function but by using lambda we dont want here\n",
        "\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp8qoqi5ai\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp8qoqi5ai', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp8qoqi5ai/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 2.1125145, step = 0\n",
            "INFO:tensorflow:global_step/sec: 494.953\n",
            "INFO:tensorflow:loss = 1.1349423, step = 100 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 597.165\n",
            "INFO:tensorflow:loss = 0.95701087, step = 200 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 600.875\n",
            "INFO:tensorflow:loss = 0.9199891, step = 300 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 605.474\n",
            "INFO:tensorflow:loss = 0.8238276, step = 400 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 604.928\n",
            "INFO:tensorflow:loss = 0.8012928, step = 500 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 579.971\n",
            "INFO:tensorflow:loss = 0.7600621, step = 600 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 583.022\n",
            "INFO:tensorflow:loss = 0.726488, step = 700 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 608.943\n",
            "INFO:tensorflow:loss = 0.7107179, step = 800 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 630.994\n",
            "INFO:tensorflow:loss = 0.6990242, step = 900 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 589.423\n",
            "INFO:tensorflow:loss = 0.6766872, step = 1000 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 602.236\n",
            "INFO:tensorflow:loss = 0.655794, step = 1100 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 615.582\n",
            "INFO:tensorflow:loss = 0.65539587, step = 1200 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 519.2\n",
            "INFO:tensorflow:loss = 0.6365433, step = 1300 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 576.321\n",
            "INFO:tensorflow:loss = 0.60933805, step = 1400 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 558.555\n",
            "INFO:tensorflow:loss = 0.6136876, step = 1500 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 568.205\n",
            "INFO:tensorflow:loss = 0.6006716, step = 1600 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 550.418\n",
            "INFO:tensorflow:loss = 0.5954843, step = 1700 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 551.032\n",
            "INFO:tensorflow:loss = 0.5767586, step = 1800 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 556.345\n",
            "INFO:tensorflow:loss = 0.5650331, step = 1900 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 584.175\n",
            "INFO:tensorflow:loss = 0.56033766, step = 2000 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 546.692\n",
            "INFO:tensorflow:loss = 0.54608595, step = 2100 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 575.54\n",
            "INFO:tensorflow:loss = 0.52753603, step = 2200 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 567.622\n",
            "INFO:tensorflow:loss = 0.52963144, step = 2300 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 507.809\n",
            "INFO:tensorflow:loss = 0.5220091, step = 2400 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 525.859\n",
            "INFO:tensorflow:loss = 0.5006572, step = 2500 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 555.496\n",
            "INFO:tensorflow:loss = 0.4931688, step = 2600 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 553.289\n",
            "INFO:tensorflow:loss = 0.49659336, step = 2700 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 572.323\n",
            "INFO:tensorflow:loss = 0.48529392, step = 2800 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 555.789\n",
            "INFO:tensorflow:loss = 0.47495168, step = 2900 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 563.116\n",
            "INFO:tensorflow:loss = 0.46916467, step = 3000 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 570.221\n",
            "INFO:tensorflow:loss = 0.4616431, step = 3100 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 567.523\n",
            "INFO:tensorflow:loss = 0.45988512, step = 3200 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 551.708\n",
            "INFO:tensorflow:loss = 0.4543301, step = 3300 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 575.614\n",
            "INFO:tensorflow:loss = 0.45041573, step = 3400 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 567.067\n",
            "INFO:tensorflow:loss = 0.43876392, step = 3500 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 599.367\n",
            "INFO:tensorflow:loss = 0.4365193, step = 3600 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 531.987\n",
            "INFO:tensorflow:loss = 0.42591447, step = 3700 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 574.637\n",
            "INFO:tensorflow:loss = 0.4338043, step = 3800 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 572.193\n",
            "INFO:tensorflow:loss = 0.42475915, step = 3900 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 551.7\n",
            "INFO:tensorflow:loss = 0.42329156, step = 4000 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.151\n",
            "INFO:tensorflow:loss = 0.40903828, step = 4100 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 566.691\n",
            "INFO:tensorflow:loss = 0.40606672, step = 4200 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.264\n",
            "INFO:tensorflow:loss = 0.40879688, step = 4300 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 551.672\n",
            "INFO:tensorflow:loss = 0.39421326, step = 4400 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 531.083\n",
            "INFO:tensorflow:loss = 0.39947736, step = 4500 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 554.04\n",
            "INFO:tensorflow:loss = 0.3834365, step = 4600 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 548.738\n",
            "INFO:tensorflow:loss = 0.39639476, step = 4700 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 581.815\n",
            "INFO:tensorflow:loss = 0.38633612, step = 4800 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 570.388\n",
            "INFO:tensorflow:loss = 0.38411906, step = 4900 (0.176 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmp8qoqi5ai/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
            "INFO:tensorflow:Loss for final step: 0.37823153.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7f7cbe7bc198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff_AbZ32clJK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "b9a61f19-9635-410a-fcf4-fe5ddde5a7e5"
      },
      "source": [
        "eval_result = classifier.evaluate(input_fn=lambda: input_fn(test, test_y, training=False)\n",
        "print('\\n Test set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-35-3a18f27f2035>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    print('\\n Test set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xitplqMNk_Hc",
        "outputId": "ed4f60d2-878d-4056-c438-352dac39a112",
        "colab": {
          "height": 420
        }
      },
      "source": [
        "#@title Introducing Colaboratory { display-mode: \"form\" }\n",
        "#@markdown This 3-minute video gives an overview of the key features of Colaboratory:\n",
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('inN8seMm7UI', width=600, height=400)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"600\"\n",
              "            height=\"400\"\n",
              "            src=\"https://www.youtube.com/embed/inN8seMm7UI\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7f956e9dda50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn_pkflio-ag",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GJBs_flRovLc"
      },
      "source": [
        "## Getting Started\n",
        "\n",
        "The document you are reading is a  [Jupyter notebook](https://jupyter.org/), hosted in Colaboratory. It is not a static page, but an interactive environment that lets you write and execute code in Python and other languages.\n",
        "\n",
        "For example, here is a **code cell** with a short Python script that computes a value, stores it in a variable, and prints the result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gJr_9dXGpJ05",
        "outputId": "5626194c-e802-4293-942d-2908885c3c1f",
        "colab": {
          "height": 35
        }
      },
      "source": [
        "seconds_in_a_day = 24 * 60 * 60\n",
        "seconds_in_a_day"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2fhs6GZ4qFMx"
      },
      "source": [
        "To execute the code in the above cell, select it with a click and then either press the play button to the left of the code, or use the keyboard shortcut \"Command/Ctrl+Enter\".\n",
        "\n",
        "All cells modify the same global state, so variables that you define by executing a cell can be used in other cells:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-gE-Ez1qtyIA",
        "outputId": "8d2e4259-4682-4e19-b683-7b9087f28820",
        "colab": {
          "height": 35
        }
      },
      "source": [
        "seconds_in_a_week = 7 * seconds_in_a_day\n",
        "seconds_in_a_week"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "604800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lSrWNr3MuFUS"
      },
      "source": [
        "For more information about working with Colaboratory notebooks, see [Overview of Colaboratory](/notebooks/basic_features_overview.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-Rh3-Vt9Nev9"
      },
      "source": [
        "## More Resources\n",
        "\n",
        "Learn how to make the most of Python, Jupyter, Colaboratory, and related tools with these resources:\n",
        "\n",
        "### Working with Notebooks in Colaboratory\n",
        "- [Overview of Colaboratory](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guide to Markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
        "- [Interactive forms](/notebooks/forms.ipynb)\n",
        "- [Interactive widgets](/notebooks/widgets.ipynb)\n",
        "- <img src=\"/img/new.png\" height=\"20px\" align=\"left\" hspace=\"4px\" alt=\"New\"></img>\n",
        " [TensorFlow 2 in Colab](/notebooks/tensorflow_version.ipynb)\n",
        "\n",
        "### Working with Data\n",
        "- [Loading data: Drive, Sheets, and Google Cloud Storage](/notebooks/io.ipynb) \n",
        "- [Charts: visualizing data](/notebooks/charts.ipynb)\n",
        "- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Machine Learning Crash Course\n",
        "These are a few of the notebooks from Google's online Machine Learning course. See the [full course website](https://developers.google.com/machine-learning/crash-course/) for more.\n",
        "- [Intro to Pandas](/notebooks/mlcc/intro_to_pandas.ipynb)\n",
        "- [Tensorflow concepts](/notebooks/mlcc/tensorflow_programming_concepts.ipynb)\n",
        "- [First steps with TensorFlow](/notebooks/mlcc/first_steps_with_tensor_flow.ipynb)\n",
        "- [Intro to neural nets](/notebooks/mlcc/intro_to_neural_nets.ipynb)\n",
        "- [Intro to sparse data and embeddings](/notebooks/mlcc/intro_to_sparse_data_and_embeddings.ipynb)\n",
        "\n",
        "### Using Accelerated Hardware\n",
        "- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n",
        "- [TensorFlow with TPUs](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P-H6Lw1vyNNd"
      },
      "source": [
        "## Machine Learning Examples: Seedbank\n",
        "\n",
        "To see end-to-end examples of the interactive machine learning analyses that Colaboratory makes possible, check out the [Seedbank](https://research.google.com/seedbank/) project.\n",
        "\n",
        "A few featured examples:\n",
        "\n",
        "- [Neural Style Transfer](https://research.google.com/seedbank/seed/neural_style_transfer_with_tfkeras): Use deep learning to transfer style between images.\n",
        "- [EZ NSynth](https://research.google.com/seedbank/seed/ez_nsynth): Synthesize audio with WaveNet auto-encoders.\n",
        "- [Fashion MNIST with Keras and TPUs](https://research.google.com/seedbank/seed/fashion_mnist_with_keras_and_tpus): Classify fashion-related images with deep learning.\n",
        "- [DeepDream](https://research.google.com/seedbank/seed/deepdream): Produce DeepDream images from your own photos.\n",
        "- [Convolutional VAE](https://research.google.com/seedbank/seed/convolutional_vae): Create a generative model of handwritten digits."
      ]
    }
  ]
}